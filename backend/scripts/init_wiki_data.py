#!/usr/bin/env python3
"""
Wikiæ•°æ®åˆå§‹åŒ–è„šæœ¬
ä»JSONLæ–‡ä»¶åˆå§‹åŒ–wikiæ•°æ®åº“
"""

import os
import sys
import json
import logging
from typing import List, Dict, Any
import argparse
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.wiki_service import WikiService
from langchain_core.documents import Document
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

class WikiDataInitializer:
    def __init__(self):
        self.wiki_service = WikiService(mode="offline")
        self.vector_db_path = "wiki_data/wiki_vectors"
        
    def init_with_jsonl_data(self, jsonl_path: str):
        """ä»JSONLæ–‡ä»¶åˆå§‹åŒ–Wikiæ•°æ®"""
        logger.info(f"ğŸš€ å¼€å§‹Wikiæ•°æ®åˆå§‹åŒ–...")
        logger.info(f"ğŸ“ æ•°æ®æº: {jsonl_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(jsonl_path):
            logger.error(f"âŒ JSONLæ–‡ä»¶ä¸å­˜åœ¨: {jsonl_path}")
            return
            
        # è¯»å–æ–‡ç« 
        articles = self._read_jsonl_articles(jsonl_path)
        if not articles:
            logger.error("âŒ æ²¡æœ‰è¯»å–åˆ°æœ‰æ•ˆçš„æ–‡ç« æ•°æ®")
            return
            
        # å¤„ç†æ–‡ç« 
        self._process_articles(articles)
        
        logger.info("ğŸ‰ Wikiæ•°æ®åˆå§‹åŒ–å®Œæˆï¼")
        
    def _read_jsonl_articles(self, jsonl_path: str) -> List[Dict[str, Any]]:
        """ä»JSONLæ–‡ä»¶è¯»å–æ–‡ç« """
        try:
            articles = []
            line_num = 0
            
            # é¦–å…ˆè®¡ç®—æ€»è¡Œæ•°
            with open(jsonl_path, 'r', encoding='utf-8') as f:
                total_lines = sum(1 for _ in f)
            
            logger.info(f"ğŸ“Š å¼€å§‹è¯»å–JSONLæ–‡ä»¶: {jsonl_path}")
            logger.info(f"ğŸ“ˆ æ–‡ä»¶æ€»è¡Œæ•°: {total_lines}")
            
            with open(jsonl_path, 'r', encoding='utf-8') as f:
                # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
                for line in tqdm(f, total=total_lines, desc="ğŸ“– è¯»å–JSONLæ–‡ä»¶", unit="è¡Œ"):
                    line_num += 1
                    line = line.strip()
                    if not line:
                        continue
                        
                    try:
                        item = json.loads(line)
                        if "title" in item and "contents" in item:
                            title_clean = item["title"].strip('"').replace(' ', '_')
                            articles.append({
                                "title": item["title"].strip('"'),  # ç§»é™¤å¼•å·
                                "content": item["contents"],
                                "summary": item["contents"][:500] + "..." if len(item["contents"]) > 500 else item["contents"],
                                "url": f"https://zh.wikipedia.org/wiki/{title_clean}",
                                "categories": [],
                                "links": []
                            })
                            
                        if line_num % 5000 == 0:
                            logger.info(f"ğŸ“Š å·²è¯»å– {line_num}/{total_lines} è¡Œï¼Œæå–äº† {len(articles)} ç¯‡æ–‡ç« ")
                            
                    except json.JSONDecodeError as e:
                        logger.warning(f"âš ï¸ ç¬¬ {line_num} è¡ŒJSONè§£æå¤±è´¥: {e}")
                        continue
                    except Exception as e:
                        logger.warning(f"âš ï¸ å¤„ç†ç¬¬ {line_num} è¡Œæ—¶å‡ºé”™: {e}")
                        continue
                        
            logger.info(f"âœ… ä»JSONLæ–‡ä»¶è¯»å–äº† {len(articles)} ç¯‡æ–‡ç« ")
            return articles
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–JSONLæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return []
            
    def _process_articles(self, articles: List[Dict[str, Any]]):
        """å¤„ç†æ–‡ç« å¹¶æ·»åŠ åˆ°å‘é‡æ•°æ®åº“"""
        try:
            logger.info(f"ğŸ”§ å¼€å§‹å¤„ç† {len(articles)} ç¯‡æ–‡ç« ...")
            
            # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
            logger.info("ğŸ”— åˆå§‹åŒ–Chromaå‘é‡æ•°æ®åº“...")
            embeddings = OllamaEmbeddings(model="nomic-embed-text")
            vectorstore = Chroma(
                collection_name="wiki_articles",
                embedding_function=embeddings,
                persist_directory=self.vector_db_path
            )
            
            # åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
            logger.info("âœ‚ï¸ åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨...")
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                length_function=len,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " ", ""]
            )
            
            # æ‰¹å¤„ç†å¤§å°é™åˆ¶
            BATCH_SIZE = 5000  # è®¾ç½®å®‰å…¨çš„æ‰¹å¤„ç†å¤§å°
            
            # å¤„ç†æ–‡ç« 
            logger.info("ğŸ“ å¼€å§‹åˆ†å‰²å’Œå‘é‡åŒ–æ–‡ç« ...")
            all_documents = []
            
            # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡å¤„ç†æ–‡ç« 
            for article in tqdm(articles, desc="ğŸ“ å¤„ç†æ–‡ç« ", unit="ç¯‡"):
                # åˆ›å»ºæ–‡æ¡£
                doc = Document(
                    page_content=article["content"],
                    metadata={
                        "title": article["title"],
                        "summary": article["summary"],
                        "url": article["url"],
                        "source": "zhwiki"
                    }
                )
                
                # åˆ†å‰²æ–‡æ¡£
                chunks = text_splitter.split_documents([doc])
                all_documents.extend(chunks)
            
            logger.info(f"âœ… æ–‡ç« å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_documents)} ä¸ªæ–‡æ¡£å—")
            
            # åˆ†æ‰¹æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            logger.info(f"ğŸ’¾ å¼€å§‹åˆ†æ‰¹æ·»åŠ åˆ°å‘é‡æ•°æ®åº“ (æ‰¹å¤§å°: {BATCH_SIZE})...")
            total_added = 0
            
            # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡æ·»åŠ æ–‡æ¡£
            for i in tqdm(range(0, len(all_documents), BATCH_SIZE), 
                         desc="ğŸ’¾ æ·»åŠ åˆ°å‘é‡æ•°æ®åº“", 
                         unit="æ‰¹"):
                batch = all_documents[i:i + BATCH_SIZE]
                vectorstore.add_documents(batch)
                total_added += len(batch)
                
                # æ¯5æ‰¹æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†è¿›åº¦
                if (i // BATCH_SIZE + 1) % 5 == 0:
                    logger.info(f"ğŸ“Š å·²æ·»åŠ  {total_added}/{len(all_documents)} ä¸ªæ–‡æ¡£å— ({total_added/len(all_documents)*100:.1f}%)")
                
            logger.info(f"âœ… å‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼å…±æ·»åŠ  {total_added} ä¸ªæ–‡æ¡£å—")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡ç« æ—¶å‡ºé”™: {e}")
            raise
            
    def get_stats(self):
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = self.wiki_service.get_database_stats()
            print(f"æœåŠ¡ç±»å‹: {stats['mode']}")
            print(f"æ–‡ç« æ€»æ•°: {stats['total_articles']}")
            print(f"æ•°æ®åº“å¤§å°: {stats['database_size']}")
            return stats
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None

def main():
    parser = argparse.ArgumentParser(description="Wikiæ•°æ®åˆå§‹åŒ–å·¥å…·")
    parser.add_argument("--jsonl-path", type=str, default="wiki_data/clean_corpus.jsonl",
                       help="JSONLæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--stats", action="store_true",
                       help="æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    
    args = parser.parse_args()
    
    initializer = WikiDataInitializer()
    
    if args.stats:
        initializer.get_stats()
        return
        
    # ä»JSONLæ–‡ä»¶åˆå§‹åŒ–
    initializer.init_with_jsonl_data(args.jsonl_path)
        
    print("âœ… Wikiæ•°æ®åˆå§‹åŒ–å®Œæˆï¼")
    print("ç°åœ¨å¯ä»¥è¿è¡Œæµ‹è¯•äº†")

if __name__ == "__main__":
    main() 
# çŸ¥è¯†åº“æœåŠ¡
# KnowledgeBaseService
# åŠŸèƒ½ï¼š
# æ–‡ä»¶ï¼š æ–‡ä»¶ä¸Šä¼ ï¼Œæ–‡ä»¶ä¸‹è½½ï¼Œæ–‡ä»¶åˆ é™¤ï¼Œæ–‡ä»¶åˆ—è¡¨è·å–ï¼Œæ–‡ä»¶çŠ¶æ€ç»´æŠ¤ï¼ˆmysqlï¼ŒçŸ¥è¯†åº“idï¼Œç”¨æˆ·idï¼Œæ–‡ä»¶idï¼‰
# å‘é‡çŸ¥è¯†åº“ï¼š ä½¿ç”¨chromaå®ç°ï¼Œå‘é‡çŸ¥è¯†åº“çš„åˆå§‹åŒ–ï¼Œå‘é‡çŸ¥è¯†åº“çš„æ›´æ–°ï¼ˆæ·»åŠ ï¼Œä¸Šä¼ ï¼Œé‡æ–°ç”Ÿæˆï¼‰ï¼Œå‘é‡çŸ¥è¯†åº“çš„ç»´æŠ¤ï¼ˆmysqlï¼ŒçŸ¥è¯†åº“idå’Œç”¨æˆ·idï¼‰
# ragé“¾ï¼šä½¿ç”¨å‘é‡æ•°æ®åº“å’ŒLLMè·å¾—æ£€ç´¢é“¾
# æ£€ç´¢ï¼šæ ¹æ®queryæ£€ç´¢çŸ¥è¯†åº“ï¼Œä½¿ç”¨æ£€ç´¢çš„ç»“æœå®Œå–„ragé“¾ï¼Œè¿”å›ragé“¾çš„æ¨ç†ç»“æœ

import os
import shutil
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from sqlalchemy.orm import Session
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import (
    UnstructuredFileLoader, 
    TextLoader,
    PyPDFLoader,
    Docx2txtLoader,
    UnstructuredPDFLoader,
    UnstructuredWordDocumentLoader
)
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma

from ..config import settings
from ..models import User, KnowledgeBase, KnowledgeFile
from .database_service import DatabaseService
from .rag_chain_service import OptimizedRAGChainService


class KnowledgeBaseService:
    """
    çŸ¥è¯†åº“æœåŠ¡ç±»
    è´Ÿè´£ç®¡ç†çŸ¥è¯†åº“çš„åˆ›å»ºã€æ–‡ä»¶ä¸Šä¼ ã€å‘é‡åŒ–ã€æ£€ç´¢ç­‰æ“ä½œ
    æ‰€æœ‰çŸ¥è¯†åº“çŠ¶æ€éƒ½è®°å½•åœ¨æ•°æ®åº“ä¸­ï¼Œæ¯ä¸ªçŸ¥è¯†åº“å¯¹åº”user_idå’Œknowledge_id
    """
    
    def __init__(self):
        self.base_upload_dir = settings.UPLOAD_DIR
        self.base_vector_dir = settings.VECTOR_DB_PATH
        
        # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
        os.makedirs(self.base_upload_dir, exist_ok=True)
        os.makedirs(self.base_vector_dir, exist_ok=True)
        
        # åˆå§‹åŒ–ä¼˜åŒ–çš„RAG ChainæœåŠ¡
        self.rag_chain_service = OptimizedRAGChainService()
    
    def create_knowledge_base(self, user_id: int, name: str, description: str = None, 
                            embedding_model: str = "nomic-embed-text", db: Session = None) -> Dict[str, Any]:
        """
        åˆ›å»ºçŸ¥è¯†åº“
        
        Args:
            user_id: ç”¨æˆ·ID
            name: çŸ¥è¯†åº“åç§°
            description: çŸ¥è¯†åº“æè¿°
            embedding_model: åµŒå…¥æ¨¡å‹åç§°
            db: æ•°æ®åº“ä¼šè¯
            
        Returns:
            Dict: åŒ…å«åˆ›å»ºç»“æœçš„å­—å…¸
        """
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“åç§°æ˜¯å¦å·²å­˜åœ¨
            existing_kb = DatabaseService.get_knowledge_base_by_name(user_id, name, db)
            if existing_kb:
                return {
                    "success": False,
                    "message": f"çŸ¥è¯†åº“åç§° '{name}' å·²å­˜åœ¨"
                }
            
            # åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
            kb_dir = os.path.join(self.base_upload_dir, f"user_{user_id}", f"kb_{name}")
            vector_dir = os.path.join(self.base_vector_dir, f"user_{user_id}", f"kb_{name}")
            os.makedirs(kb_dir, exist_ok=True)
            os.makedirs(vector_dir, exist_ok=True)
            
            # åˆ›å»ºçŸ¥è¯†åº“è®°å½•
            knowledge_base = DatabaseService.create_knowledge_base(
                user_id=user_id,
                name=name,
                description=description,
                embedding_model=embedding_model,
                vector_db_path=vector_dir,
                db=db
            )
            
            if knowledge_base:
                return {
                    "success": True,
                    "message": f"çŸ¥è¯†åº“ '{name}' åˆ›å»ºæˆåŠŸ",
                    "knowledge_base_id": knowledge_base.id
                }
            else:
                return {
                    "success": False,
                    "message": "çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥"
                }
                
        except Exception as e:
            return {
                "success": False,
                "message": f"åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {str(e)}"
            }
    
    def upload_file_to_knowledge_base(self, knowledge_base_id: int, user_id: int, 
                                    file, db: Session = None) -> Dict[str, Any]:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®šçŸ¥è¯†åº“
        
        Args:
            knowledge_base_id: çŸ¥è¯†åº“ID
            user_id: ç”¨æˆ·ID
            file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
            db: æ•°æ®åº“ä¼šè¯
            
        Returns:
            Dict: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
        """
        try:
            # éªŒè¯çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨ä¸”å±äºè¯¥ç”¨æˆ·
            knowledge_base = DatabaseService.get_knowledge_base_by_id(knowledge_base_id, user_id, db)
            if not knowledge_base:
                return {
                    "success": False,
                    "message": "çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
                }
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if hasattr(file, 'size') and file.size and file.size > settings.MAX_FILE_SIZE:
                return {
                    "success": False,
                    "message": f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({settings.MAX_FILE_SIZE / 1024 / 1024}MB)"
                }
            
            # ç”Ÿæˆæ–‡ä»¶åå’Œè·¯å¾„
            original_filename = file.filename
            if original_filename and '/' in original_filename:
                actual_filename = os.path.basename(original_filename)
            else:
                actual_filename = original_filename
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_extension = actual_filename.split('.')[-1].lower() if '.' in actual_filename else 'txt'
            unique_filename = f"{timestamp}_{actual_filename}"
            
            # ä¿å­˜æ–‡ä»¶
            kb_upload_dir = os.path.join(self.base_upload_dir, f"user_{user_id}", f"kb_{knowledge_base.name}")
            file_path = os.path.join(kb_upload_dir, unique_filename)
            
            with open(file_path, "wb") as f:
                shutil.copyfileobj(file.file, f)
            
            # å¤„ç†æ–‡æ¡£
            documents = self._process_document(file_path, file_extension)
            if not documents:
                return {
                    "success": False,
                    "message": "æ–‡æ¡£å¤„ç†å¤±è´¥: æœªèƒ½æå–æœ‰æ•ˆå†…å®¹"
                }
            
            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            success = self._add_documents_to_vectorstore(documents, knowledge_base.vector_db_path, knowledge_base.embedding_model)
            if not success:
                return {
                    "success": False,
                    "message": "å‘é‡åŒ–å¤„ç†å¤±è´¥"
                }
            
            # ä¿å­˜æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“
            knowledge_file = DatabaseService.create_knowledge_file(
                knowledge_base_id=knowledge_base_id,
                filename=unique_filename,
                original_filename=original_filename,
                file_path=file_path,
                file_size=os.path.getsize(file_path),
                file_type=file_extension,
                document_count=len(documents),
                is_processed=True,
                db=db
            )
            
            if knowledge_file:
                # æ›´æ–°çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
                DatabaseService.update_knowledge_base_stats(knowledge_base_id, db)
                
                return {
                    "success": True,
                    "message": f"æ–‡ä»¶ '{original_filename}' ä¸Šä¼ æˆåŠŸå¹¶å·²å‘é‡åŒ–",
                    "chunks": len(documents),
                    "file_id": knowledge_file.id
                }
            else:
                return {
                    "success": False,
                    "message": "æ–‡ä»¶è®°å½•ä¿å­˜å¤±è´¥"
                }
                
        except Exception as e:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'file_path' in locals() and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
            return {
                "success": False,
                "message": f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
            }
    
    def get_rag_context(self, user_id: int, message: str, top_k: int = 3, db: Session = None) -> str:
        """
        è·å–RAGä¸Šä¸‹æ–‡ - ä»ç”¨æˆ·çš„æ‰€æœ‰çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            user_id: ç”¨æˆ·ID
            message: ç”¨æˆ·æ¶ˆæ¯
            top_k: æ£€ç´¢çš„æ–‡æ¡£æ•°é‡
            db: æ•°æ®åº“ä¼šè¯
            
        Returns:
            str: RAGä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        try:
            # è·å–ç”¨æˆ·çš„æ‰€æœ‰æ´»è·ƒçŸ¥è¯†åº“
            knowledge_bases = DatabaseService.get_user_active_knowledge_bases(user_id, db)
            if not knowledge_bases:
                print("æ²¡æœ‰æ´»è·ƒçŸ¥è¯†åº“")
                return ""
            
            all_results = []
            
            # ä»æ¯ä¸ªçŸ¥è¯†åº“ä¸­æ£€ç´¢
            for kb in knowledge_bases:
                print(f"æ£€ç´¢çŸ¥è¯†åº“: {kb.name}")
                if kb.vector_db_path and os.path.exists(kb.vector_db_path):
                    results = self._search_knowledge_base(message, kb.vector_db_path, kb.embedding_model, top_k)
                    all_results.extend(results)
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶å–å‰top_kä¸ª
            all_results.sort(key=lambda x: x[1], reverse=True)
            print(f"æ’åºåçš„ç»“æœ: {all_results}")   
            top_results = all_results[:top_k]
            
            if not top_results:
                return ""
            
            # ç”Ÿæˆä¸Šä¸‹æ–‡
            context_parts = []
            for doc, score in top_results:
                context_parts.append(doc.page_content)
            
            context = "\n".join(context_parts)
            print(f"RAGæ£€ç´¢åˆ° {len(top_results)} æ¡ç›¸å…³æ–‡æ¡£")
            
            return f"\n\nç›¸å…³æ–‡æ¡£ä¿¡æ¯ï¼š\n{context}\n\nåŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”ï¼š"
            
        except Exception as e:
            print(f"RAGä¸Šä¸‹æ–‡ç”Ÿæˆå¤±è´¥: {str(e)}")
            return ""
    
    def _process_document(self, file_path: str, file_type: str) -> List[Document]:
        """å¤„ç†æ–‡æ¡£å¹¶è¿”å›åˆ†å‰²åçš„æ–‡æ¡£å—ï¼Œä½¿ç”¨ä¼˜åŒ–çš„æ–‡æœ¬åˆ†å‰²å’Œæ ‡é¢˜å¢å¼º"""
        print(f"å¼€å§‹å¤„ç†æ–‡æ¡£: {file_path}, ç±»å‹: {file_type}")
        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åŠ è½½å™¨
            if file_type in ['txt', 'md']:
                loader = TextLoader(file_path)
            elif file_type == 'pdf':
                try:
                    loader = PyPDFLoader(file_path)
                except Exception:
                    print("PyPDFLoader å¤±è´¥,ä½¿ç”¨ UnstructuredPDFLoader")
                    loader = UnstructuredPDFLoader(file_path)
            elif file_type in ['docx', 'doc']:
                try:
                    loader = Docx2txtLoader(file_path)
                except Exception:
                    print("Docx2txtLoader å¤±è´¥,ä½¿ç”¨ UnstructuredWordDocumentLoader")
                    loader = UnstructuredWordDocumentLoader(file_path)
            else:
                loader = UnstructuredFileLoader(file_path)
            
            documents = loader.load()
            
            # ä½¿ç”¨ä¼˜åŒ–çš„æ–‡æ¡£å¤„ç†ï¼ˆä¸­æ–‡æ–‡æœ¬åˆ†å‰² + æ ‡é¢˜å¢å¼ºï¼‰
            processed_documents = self.rag_chain_service.process_documents_with_enhancement(
                documents=documents,
                chunk_size=settings.CHUNK_SIZE,
                chunk_overlap=settings.CHUNK_OVERLAP,
                use_title_enhance=True
            )
            
            return processed_documents
        except Exception as e:
            print(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
            return []
    
    def _add_documents_to_vectorstore(self, documents: List[Document], vector_db_path: str, embedding_model: str) -> bool:
        """å°†æ–‡æ¡£æ·»åŠ åˆ°æŒ‡å®šçŸ¥è¯†åº“çš„å‘é‡æ•°æ®åº“"""
        try:
            embeddings = OllamaEmbeddings(model=embedding_model)
            vectorstore = Chroma(
                persist_directory=vector_db_path,
                embedding_function=embeddings
            )
            
            if documents:
                vectorstore.add_documents(documents)
                print(f"æˆåŠŸæ·»åŠ  {len(documents)} æ¡æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“: {vector_db_path}")
                return True
        except Exception as e:
            print(f"æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {str(e)}")
        return False
    
    def _search_knowledge_base(self, query: str, vector_db_path: str, embedding_model: str, top_k: int) -> List[Tuple[Document, float]]:
        """ä»æŒ‡å®šçŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            embeddings = OllamaEmbeddings(model=embedding_model)
            vectorstore = Chroma(
                persist_directory=vector_db_path,
                embedding_function=embeddings
            )
            retriever = vectorstore.as_retriever(
                search_type="similarity_score_threshold", 
                search_kwargs={"k": top_k, "score_threshold": 0.8}  # æ·»åŠ ç›¸ä¼¼åº¦é˜ˆå€¼
            )
            docs = retriever.get_relevant_documents(query)
            
            results = []
            for doc in docs:
                results.append((doc.page_content, 1.0))  # ç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥è·å–ç›¸ä¼¼åº¦åˆ†æ•°
            
            return results
        except Exception as e:
            print(f"çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {str(e)}")
            return []
    
    def _delete_vectors_from_chroma(self, vector_db_path: str, filename: str) -> bool:
        """ä»ChromaDBä¸­åˆ é™¤æŒ‡å®šæ–‡ä»¶çš„å‘é‡æ•°æ®"""
        try:
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
            embeddings = OllamaEmbeddings(model="nomic-embed-text")
            
            # åŠ è½½å‘é‡æ•°æ®åº“
            vectorstore = Chroma(
                persist_directory=vector_db_path,
                embedding_function=embeddings
            )
            
            # è·å–æ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®
            collection = vectorstore._collection
            
            # è·å–æ‰€æœ‰æ–‡æ¡£
            all_results = collection.get()
            
            if not all_results['ids']:
                print(f"ChromaDBä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
                return False
            
            # æŸ¥æ‰¾åŒ…å«è¯¥æ–‡ä»¶åçš„æ–‡æ¡£
            matching_ids = []
            for i, metadata in enumerate(all_results['metadatas']):
                if metadata and 'source' in metadata:
                    source_path = metadata['source']
                    # ä»sourceè·¯å¾„ä¸­æå–æ–‡ä»¶å
                    source_filename = os.path.basename(source_path)
                    # ä»åŸå§‹æ–‡ä»¶åä¸­æå–æ–‡ä»¶åï¼ˆå»æ‰è·¯å¾„ï¼‰
                    original_filename = os.path.basename(filename)
                    
                    print(f"æ¯”è¾ƒ: source_filename='{source_filename}' vs original_filename='{original_filename}'")
                    
                    # æ£€æŸ¥åŸå§‹æ–‡ä»¶åæ˜¯å¦åŒ…å«åœ¨sourceæ–‡ä»¶åä¸­ï¼ˆå¤„ç†æ—¶é—´æˆ³å‰ç¼€ï¼‰
                    if original_filename in source_filename:
                        matching_ids.append(all_results['ids'][i])
                        print(f"æ‰¾åˆ°åŒ¹é…æ–‡æ¡£: {source_path}")
            
            if matching_ids:
                # åˆ é™¤åŒ¹é…çš„å‘é‡æ•°æ®
                collection.delete(ids=matching_ids)
                print(f"ä»ChromaDBä¸­åˆ é™¤äº† {len(matching_ids)} ä¸ªå‘é‡")
                return True
            else:
                print(f"åœ¨ChromaDBä¸­æœªæ‰¾åˆ°æ–‡ä»¶ '{filename}' çš„å‘é‡æ•°æ®")
                return False
                
        except Exception as e:
            print(f"ä»ChromaDBåˆ é™¤å‘é‡æ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def get_user_knowledge_bases(self, user_id: int, db: Session = None) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„çŸ¥è¯†åº“åˆ—è¡¨"""
        try:
            print(f"æ­£åœ¨ä»æ•°æ®åº“è·å–ç”¨æˆ· {user_id} çš„çŸ¥è¯†åº“...")
            knowledge_bases = DatabaseService.get_user_knowledge_bases(user_id, db)
            print(f"ä»æ•°æ®åº“è·å–åˆ° {len(knowledge_bases)} ä¸ªçŸ¥è¯†åº“")
            
            result = []
            for kb in knowledge_bases:
                try:
                    kb_dict = {
                        "id": kb.id,
                        "user_id": kb.user_id,
                        "name": kb.name,
                        "description": kb.description,
                        "embedding_model": kb.embedding_model,
                        "vector_db_path": kb.vector_db_path,
                        "file_count": kb.file_count,
                        "document_count": kb.document_count,
                        "is_active": kb.is_active,
                        "created_at": kb.created_at,
                        "updated_at": kb.updated_at
                    }
                    result.append(kb_dict)
                except Exception as kb_error:
                    print(f"å¤„ç†çŸ¥è¯†åº“å¯¹è±¡æ—¶å‡ºé”™: {kb_error}")
                    print(f"çŸ¥è¯†åº“å¯¹è±¡: {kb}")
                    continue
            
            print(f"æˆåŠŸå¤„ç† {len(result)} ä¸ªçŸ¥è¯†åº“")
            return result
        except Exception as e:
            print(f"è·å–ç”¨æˆ·çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def get_knowledge_base_files(self, knowledge_base_id: int, user_id: int, db: Session = None) -> List[Dict[str, Any]]:
        """è·å–çŸ¥è¯†åº“çš„æ–‡ä»¶åˆ—è¡¨"""
        try:
            files = DatabaseService.get_knowledge_base_files(knowledge_base_id, user_id, db)
            result = []
            for file in files:
                result.append({
                    "id": file.id,
                    "filename": file.filename,
                    "original_filename": file.original_filename,
                    "file_path": file.file_path,
                    "file_size": file.file_size,
                    "file_type": file.file_type,
                    "document_count": file.document_count,
                    "is_processed": file.is_processed,
                    "created_at": file.created_at,
                    "updated_at": file.updated_at
                })
            return result
        except Exception as e:
            print(f"è·å–çŸ¥è¯†åº“æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def delete_knowledge_base(self, knowledge_base_id: int, user_id: int, db: Session = None) -> Dict[str, Any]:
        """åˆ é™¤çŸ¥è¯†åº“"""
        try:
            # éªŒè¯çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨ä¸”å±äºè¯¥ç”¨æˆ·
            knowledge_base = DatabaseService.get_knowledge_base_by_id(knowledge_base_id, user_id, db)
            if not knowledge_base:
                return {
                    "success": False,
                    "message": "çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
                }
            
            # åˆ é™¤å‘é‡æ•°æ®åº“æ–‡ä»¶
            if knowledge_base.vector_db_path and os.path.exists(knowledge_base.vector_db_path):
                shutil.rmtree(knowledge_base.vector_db_path)
            
            # åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
            kb_upload_dir = os.path.join(self.base_upload_dir, f"user_{user_id}", f"kb_{knowledge_base.name}")
            if os.path.exists(kb_upload_dir):
                shutil.rmtree(kb_upload_dir)
            
            # åˆ é™¤æ•°æ®åº“è®°å½•
            success = DatabaseService.delete_knowledge_base(knowledge_base_id, user_id, db)
            
            if success:
                return {
                    "success": True,
                    "message": f"çŸ¥è¯†åº“ '{knowledge_base.name}' åˆ é™¤æˆåŠŸ"
                }
            else:
                return {
                    "success": False,
                    "message": "åˆ é™¤çŸ¥è¯†åº“å¤±è´¥"
                }
                
        except Exception as e:
            return {
                "success": False,
                "message": f"åˆ é™¤çŸ¥è¯†åº“å¤±è´¥: {str(e)}"
            }
    
    def delete_file_from_knowledge_base(self, file_id: int, knowledge_base_id: int, user_id: int, db: Session = None) -> Dict[str, Any]:
        """ä»çŸ¥è¯†åº“ä¸­åˆ é™¤æ–‡ä»¶"""
        try:
            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å±äºè¯¥çŸ¥è¯†åº“
            knowledge_file = DatabaseService.get_knowledge_file_by_id(file_id, knowledge_base_id, user_id, db)
            if not knowledge_file:
                return {
                    "success": False,
                    "message": "æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
                }
            
            # è·å–çŸ¥è¯†åº“ä¿¡æ¯
            knowledge_base = DatabaseService.get_knowledge_base_by_id(knowledge_base_id, user_id, db)
            if not knowledge_base:
                return {
                    "success": False,
                    "message": "çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
                }
            
            # åˆ é™¤ç‰©ç†æ–‡ä»¶
            if os.path.exists(knowledge_file.file_path):
                os.remove(knowledge_file.file_path)
            
            # ä»ChromaDBä¸­åˆ é™¤å‘é‡æ•°æ®
            try:
                if knowledge_base.vector_db_path and os.path.exists(knowledge_base.vector_db_path):
                    print(f"å¼€å§‹ä»ChromaDBåˆ é™¤æ–‡ä»¶ '{knowledge_file.original_filename}' çš„å‘é‡æ•°æ®...")
                    print(f"å‘é‡æ•°æ®åº“è·¯å¾„: {knowledge_base.vector_db_path}")
                    # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºè¿‡æ»¤æ¡ä»¶åˆ é™¤å‘é‡æ•°æ®
                    success = self._delete_vectors_from_chroma(knowledge_base.vector_db_path, knowledge_file.original_filename)
                    if success:
                        print(f"âœ… å·²ä»ChromaDBä¸­åˆ é™¤æ–‡ä»¶ '{knowledge_file.original_filename}' çš„å‘é‡æ•°æ®")
                    else:
                        print(f"âŒ ä»ChromaDBåˆ é™¤æ–‡ä»¶ '{knowledge_file.original_filename}' çš„å‘é‡æ•°æ®å¤±è´¥")
                else:
                    print(f"âš ï¸ å‘é‡æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {knowledge_base.vector_db_path}")
            except Exception as e:
                print(f"ä»ChromaDBåˆ é™¤å‘é‡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()
                # å³ä½¿å‘é‡åˆ é™¤å¤±è´¥ï¼Œä¹Ÿç»§ç»­åˆ é™¤å…¶ä»–æ•°æ®
            
            # åˆ é™¤æ•°æ®åº“è®°å½•
            success = DatabaseService.delete_knowledge_file(file_id, knowledge_base_id, user_id, db)
            
            if success:
                # æ›´æ–°çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
                DatabaseService.update_knowledge_base_stats(knowledge_base_id, db)
                
                return {
                    "success": True,
                    "message": f"æ–‡ä»¶ '{knowledge_file.original_filename}' åˆ é™¤æˆåŠŸ"
                }
            else:
                return {
                    "success": False,
                    "message": "åˆ é™¤æ–‡ä»¶å¤±è´¥"
                }
                
        except Exception as e:
            return {
                "success": False,
                "message": f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}"
            }


    def create_rag_chain_for_user(
        self, 
        user_id: int, 
        llm, 
        chain_type: str = "stuff",
        use_reranker: bool = True,
        top_k: int = 5,
        score_threshold: float = 0.5,
        use_wiki: bool = False,  # æ·»åŠ WikiçŸ¥è¯†æ”¯æŒ
        db: Session = None
    ):
        """
        ä¸ºç”¨æˆ·åˆ›å»ºRAG Chain
        
        Args:
            user_id: ç”¨æˆ·ID
            llm: è¯­è¨€æ¨¡å‹
            chain_type: Chainç±»å‹
            use_reranker: æ˜¯å¦ä½¿ç”¨é‡æ’åº
            top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡
            score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            use_wiki: æ˜¯å¦ä½¿ç”¨WikiçŸ¥è¯†
            db: æ•°æ®åº“ä¼šè¯
            
        Returns:
            RAG Chainå®ä¾‹æˆ–None
        """
        try:
            # å¦‚æœå¯ç”¨WikiçŸ¥è¯†ï¼Œä¼˜å…ˆä½¿ç”¨WikiçŸ¥è¯†åº“
            if use_wiki:
                print("ğŸ” ä½¿ç”¨WikiçŸ¥è¯†åº“è¿›è¡ŒRAG")
                
                # ä½¿ç”¨å·²ç»åˆå§‹åŒ–çš„wikiæœåŠ¡
                if hasattr(self.rag_chain_service, 'wiki_kb') and self.rag_chain_service.wiki_kb:
                    wiki_service = self.rag_chain_service.wiki_kb.wiki_service
                    
                    # æ£€æŸ¥Wikiæ•°æ®åº“æ˜¯å¦å¯ç”¨
                    stats = wiki_service.get_database_stats()
                    if stats.get("service_type") in ["online", "offline"]:
                        print(f"âœ… Wikiæ•°æ®åº“å¯ç”¨ï¼Œæ¨¡å¼: {wiki_service.mode}")
                        if stats.get("service_type") == "offline":
                            print(f"   åŒ…å« {stats['stats']['total_articles']} ç¯‡æ–‡ç« ")
                        # ä½¿ç”¨WikiçŸ¥è¯†åº“åˆ›å»ºRAG Chain
                        return self.rag_chain_service.create_rag_chain_with_wiki(
                            wiki_service=wiki_service,
                            llm=llm,
                            chain_type=chain_type,
                            use_reranker=use_reranker,
                            top_k=top_k,
                            score_threshold=score_threshold
                        )
                    else:
                        print("âš ï¸ Wikiæ•°æ®åº“ä¸å¯ç”¨ï¼Œå›é€€åˆ°ç”¨æˆ·çŸ¥è¯†åº“")
                else:
                    print("âš ï¸ WikiæœåŠ¡æœªåˆå§‹åŒ–ï¼Œå›é€€åˆ°ç”¨æˆ·çŸ¥è¯†åº“")
            
            # è·å–ç”¨æˆ·çš„ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥æ”¯æŒå¤šçŸ¥è¯†åº“ï¼‰
            knowledge_bases = DatabaseService.get_user_knowledge_bases(user_id, db)
            
            if not knowledge_bases:
                print(f"ç”¨æˆ· {user_id} æ²¡æœ‰çŸ¥è¯†åº“")
                return None
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“
            kb = knowledge_bases[0]
            vector_db_path = kb.vector_db_path
            
            # åˆ›å»ºRAG Chain
            rag_chain = self.rag_chain_service.create_rag_chain(
                vector_db_path=vector_db_path,
                llm=llm,
                chain_type=chain_type,
                use_reranker=use_reranker,
                top_k=top_k,
                score_threshold=score_threshold
            )
            
            return rag_chain
            
        except Exception as e:
            print(f"åˆ›å»ºRAG Chainå¤±è´¥: {str(e)}")
            return None
    
    def create_simple_chat_chain(
        self,
        llm
    ):
        """
        åˆ›å»ºç®€å•èŠå¤©Chainï¼ˆä¸ä½¿ç”¨Promptæ¨¡æ¿ï¼‰
        
        Args:
            llm: è¯­è¨€æ¨¡å‹
            
        Returns:
            ç®€å•èŠå¤©Chainå®ä¾‹
        """
        return self.rag_chain_service.create_simple_chat_chain(llm)
    
    def create_chat_chain(
        self,
        llm,
        prompt_name: str = "chat_default"
    ):
        """
        åˆ›å»ºèŠå¤©Chain
        
        Args:
            llm: è¯­è¨€æ¨¡å‹
            prompt_name: Promptæ¨¡æ¿åç§°
            
        Returns:
            èŠå¤©Chainå®ä¾‹
        """
        return self.rag_chain_service.create_chat_chain(llm, prompt_name)
    
    def create_generation_chain(
        self,
        llm,
        prompt_name: str
    ):
        """
        åˆ›å»ºç”Ÿæˆä»»åŠ¡Chain
        
        Args:
            llm: è¯­è¨€æ¨¡å‹
            prompt_name: Promptæ¨¡æ¿åç§°
            
        Returns:
            ç”ŸæˆChainå®ä¾‹
        """
        return self.rag_chain_service.create_generation_chain(llm, prompt_name)
    
    def get_available_prompts(self):
        """è·å–å¯ç”¨çš„Promptæ¨¡æ¿"""
        return self.rag_chain_service.get_available_prompts()
    
    def get_chain_types(self):
        """è·å–å¯ç”¨çš„Chainç±»å‹"""
        return self.rag_chain_service.get_chain_types()


# å…¨å±€çŸ¥è¯†åº“æœåŠ¡å®ä¾‹
knowledge_base_service = KnowledgeBaseService()
